{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# General packages: Operating System Interface, System-specific parameters and functions, \n",
    "# Regular expression operations, Unix style pathname pattern expansion\n",
    "import os, platform, sys, re, json, glob\n",
    "\n",
    "# Statistics from text functions, Date-parsing and manipulation\n",
    "from textstat.textstat import textstat\n",
    "import time\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import calendar\n",
    "\n",
    "# Function for determing if string is a date\n",
    "def is_date(string):\n",
    "    try: \n",
    "        dateutil.parser.parse(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Function for converting a datetime to timestamp\n",
    "def returnts(datestring):\n",
    "    x = dateutil.parser.parse(datestring)\n",
    "    stamp = calendar.timegm(x.timetuple())\n",
    "    y = datetime.datetime.utcfromtimestamp(stamp)\n",
    "    return stamp\n",
    "\n",
    "# Function for finding file creation date\n",
    "def creation_date(path_to_file):\n",
    "    \"\"\"\n",
    "    Try to get the date that a file was created, falling back to when it was\n",
    "    last modified if that isn't possible.\n",
    "    See http://stackoverflow.com/a/39501288/1709587 for explanation.\n",
    "    \"\"\"\n",
    "    if platform.system() == 'Windows':\n",
    "        return os.path.getctime(path_to_file)\n",
    "    else:\n",
    "        stat = os.stat(path_to_file)\n",
    "        try:\n",
    "            return stat.st_birthtime\n",
    "        except AttributeError:\n",
    "            # We're probably on Linux. No easy way to get creation dates here,\n",
    "            # so we'll settle for when its content was last modified.\n",
    "            return stat.st_mtime\n",
    "\n",
    "# Function for replacing word with word from a dictionary\n",
    "def multiwordReplace(text, wordDic):\n",
    "    \"\"\"\n",
    "    take a text and replace words that match a key in a dictionary with\n",
    "    the associated value, return the changed text\n",
    "    \"\"\"\n",
    "    rc = re.compile('|'.join(map(re.escape, wordDic)))\n",
    "    def translate(match):\n",
    "        return wordDic[match.group(0)]\n",
    "    return rc.sub(translate, text)\n",
    "\n",
    "# Norwegian to English month-dictionary\n",
    "monthDict = {\n",
    "    'januar': 'january',\n",
    "    'februar': 'february',\n",
    "    'mars': 'march',\n",
    "    'april': 'april',\n",
    "    'mai': 'may',\n",
    "    'juni': 'june',\n",
    "    'juli': 'july',\n",
    "    'august': 'august',\n",
    "    'september': 'september',\n",
    "    'oktober': 'october',\n",
    "    'november': 'november',\n",
    "    'desember': 'december'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Operations\n",
    "Based on `DocToTXT.vba`, which produces clean .txt-versions of .doc-files in ANSI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# *NOTE*: This operation requires significant processing power and time.\n",
    "\n",
    "data = {}\n",
    "\n",
    "# Define common introductions to Applications\n",
    "intro_strings = ('Application to', 'Søknad til')\n",
    "# Define common endings to Applications\n",
    "outro_strings = ('Best regards', 'Med vennlig hilsen')\n",
    "# Define locations prepending dates in Applications\n",
    "locations = {'Bergen':'', 'Oslo':'', 'Tromsø':''}\n",
    "\n",
    "# Declare known Applications yielding an interview\n",
    "interviews = ('IMDi Vest', 'Manpower', 'NHH', 'Nord Universitet', 'PVS', 'Ramsalt', 'SampolSosiologi')\n",
    "# Declare known Applications yielding an offer\n",
    "offers = ('Eksamensvakt, UiB', 'IMDi Vest', 'Manpower', 'NHH', 'PVS', 'Sixt Biluteleie AS')\n",
    "# Declare known Applications yielding a reply\n",
    "replies = ('AdmOrg', 'Null')\n",
    "\n",
    "# Loop over converted .txt-files, counting iteratively\n",
    "index = 0\n",
    "for f in glob.glob('./Data/DocConverted/*.txt'):\n",
    "    # Assume `latin-1` encoding, commensurate with MS Word saving as ANSI\n",
    "    inputfile = open(f, 'r', encoding='latin-1')\n",
    "    # Read file by lines\n",
    "    lines = inputfile.readlines()\n",
    "    inputfile.close()\n",
    "    # Clean up title\n",
    "    title = f.replace('./Data/DocConverted', '').replace('\\\\', '').replace(' - Ole Vik.txt', '')\n",
    "    \n",
    "    data[index] = {}\n",
    "    data[index]['Title'] = title\n",
    "    data[index]['Date'] = None\n",
    "    \n",
    "    # Iterate over lines\n",
    "    for num, line in enumerate(lines, 1):\n",
    "        if any(string in line for string in locations):\n",
    "            date = line\n",
    "            for k, v in locations.items():\n",
    "                date = date.replace(k + ' ', v)\n",
    "            # Convert month-names for date-recognition\n",
    "            date = multiwordReplace(date, monthDict)\n",
    "            if is_date(date):\n",
    "                timestamp = returnts(date)\n",
    "                data[index]['Date'] = timestamp\n",
    "        # Search for start of Application\n",
    "        if any(string in line for string in intro_strings):\n",
    "            intro = num\n",
    "        # Search for end of Application\n",
    "        if any(string in line for string in outro_strings):\n",
    "            outro = num\n",
    "    # Compile Application from start to end, assign as `Content`\n",
    "    obscured_lines = lines[intro:outro]\n",
    "    data[index]['Content'] = (obscured_lines)\n",
    "    \n",
    "    joined_content = ' '.join(obscured_lines)    \n",
    "    \n",
    "    # Check for and assign Interview, Offer, Reply\n",
    "    data[index]['Results'] = {}\n",
    "    if any(string == title for string in interviews):\n",
    "        data[index]['Results']['Interview'] = True\n",
    "    else:\n",
    "        data[index]['Results']['Interview'] = False\n",
    "    if any(string == title for string in offers):\n",
    "        data[index]['Results']['Offer'] = True\n",
    "    else:\n",
    "        data[index]['Results']['Offer'] = False\n",
    "    if any(string == title for string in replies):\n",
    "        data[index]['Results']['Reply'] = True\n",
    "    else:\n",
    "        data[index]['Results']['Reply'] = False\n",
    "    \n",
    "    # Assign descriptive statistics\n",
    "    data[index]['Descriptive'] = {}\n",
    "    data[index]['Descriptive']['Words'] = textstat.lexicon_count(obscured_lines)\n",
    "    data[index]['Descriptive']['Sentences'] = textstat.sentence_count(joined_content)\n",
    "    data[index]['Descriptive']['Lines'] = len(obscured_lines)\n",
    "    #data[index]['Descriptive']['Paragraphs'] = None\n",
    "    \n",
    "    # Create analytical readability-statistics\n",
    "    analytical = {\n",
    "        'flesch_reading_ease': textstat.flesch_reading_ease(joined_content),\n",
    "        'smog_index': textstat.smog_index(joined_content),\n",
    "        'flesch_kincaid_grade': textstat.flesch_kincaid_grade(joined_content),\n",
    "        'coleman_liau_index': textstat.coleman_liau_index(joined_content),\n",
    "        'automated_readability_index': textstat.automated_readability_index(joined_content),\n",
    "        'dale_chall_readability_score': textstat.dale_chall_readability_score(joined_content),\n",
    "        'difficult_words': textstat.difficult_words(joined_content),\n",
    "        'linsear_write_formula': textstat.linsear_write_formula(joined_content),\n",
    "        'gunning_fog': textstat.gunning_fog(joined_content),\n",
    "        'text_standard': textstat.text_standard(joined_content)\n",
    "    }\n",
    "    \n",
    "    # Assign analytical statistics\n",
    "    data[index]['Analytical'] = {}\n",
    "    data[index]['Analytical']['Readability'] = analytical\n",
    "    #data[index]['Analytical']['Clarity'] = {}\n",
    "    #data[index]['Analytical']['Applicability'] = {}\n",
    "        \n",
    "    original_file = f.replace('./Data/DocConverted', './Data/Doc').replace('.txt', '.doc')\n",
    "    data[index]['creation_date'] = creation_date(original_file)\n",
    "    data[index]['modification_date'] = os.path.getmtime(original_file)\n",
    "    \n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Data/Applications.json with 107 items.\n"
     ]
    }
   ],
   "source": [
    "# Save `data` to JSON-file\n",
    "try:\n",
    "    with open('Data/Applications.json', 'w') as json_file:\n",
    "        json.dump(data, json_file, ensure_ascii=False)\n",
    "    pass\n",
    "except IOError as e:\n",
    "    print (e)\n",
    "    pass\n",
    "finally:\n",
    "    print ('Saved Data/Applications.json with ' + str(len(data)) + ' items.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
